# TESS è®­ç»ƒç¯å¢ƒå‡†å¤‡æ€»ç»“

## âœ… å·²å®Œæˆçš„å·¥ä½œ

### 1. ä¾èµ–å…¼å®¹æ€§åˆ†æ
å·²åˆ›å»ºè¯¦ç»†çš„å…¼å®¹æ€§åˆ†ææ–‡æ¡£ï¼š`COMPATIBILITY_ANALYSIS.md`

**ä¸»è¦å‘ç°**:
- âœ… Python 3.9 - å…¼å®¹
- âœ… PyTorch 2.2.0 - å…¼å®¹
- âœ… Transformers 4.33.3 - å…¼å®¹ï¼ˆéœ€ä¿®å¤ AdamW å¯¼å…¥ï¼‰
- âœ… Diffusers 0.27.2 - å…¼å®¹ï¼ˆéœ€ä¿®å¤æ‹¼å†™é”™è¯¯ï¼‰
- âœ… Datasets 2.14.6 - å…¼å®¹
- âœ… å…¶ä»–ä¾èµ– - å…¨éƒ¨å…¼å®¹

### 2. å…³é”®ä»£ç ä¿®å¤

#### ä¿®å¤ 1: AdamW ä¼˜åŒ–å™¨è¿ç§»
**æ–‡ä»¶**: `sdlm/trainer.py`
**é—®é¢˜**: Transformers 4.33.3 å·²åºŸå¼ƒ `from transformers import AdamW`
**ä¿®å¤**: æ”¹ç”¨ `from torch.optim import AdamW`
**çŠ¶æ€**: âœ… å·²ä¿®å¤å¹¶éªŒè¯

```python
# ç¬¬ 48 è¡Œ - å·²ä¿®å¤
from torch.optim import AdamW

# ç¬¬ 707 è¡Œ - æ— éœ€ä¿®æ”¹ï¼ˆè°ƒç”¨æ–¹å¼ç›¸åŒï¼‰
self.optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate)
```

#### ä¿®å¤ 2: Torch æ•°æ®ç±»å‹æ‹¼å†™
**æ–‡ä»¶**: `sdlm/schedulers/scheduling_simplex_ddpm.py`
**é—®é¢˜**: `torch.torch.float32` æ‹¼å†™é”™è¯¯
**ä¿®å¤**: æ”¹ä¸º `torch.float32`
**çŠ¶æ€**: âœ… å·²ä¿®å¤å¹¶éªŒè¯

```python
# ç¬¬ 66 è¡Œ - å·²ä¿®å¤
return betas, torch.tensor(alphas_cumprod, dtype=torch.float32, device=device)
```

### 3. éªŒè¯è„šæœ¬

#### è„šæœ¬ 1: verify_compatibility.py
**ç”¨é€”**: éªŒè¯ä»£ç ä¿®å¤æ˜¯å¦æ­£ç¡®åº”ç”¨
**è¿è¡Œ**: `python verify_compatibility.py`
**ç»“æœ**: âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡

#### è„šæœ¬ 2: verify_environment.py
**ç”¨é€”**: éªŒè¯ç¯å¢ƒä¾èµ–ç‰ˆæœ¬æ˜¯å¦æ­£ç¡®å®‰è£…
**è¿è¡Œ**: `python verify_environment.py` (éœ€è¦å…ˆå®‰è£…ç¯å¢ƒ)
**ç”¨é€”**: å®‰è£…ç¯å¢ƒåä½¿ç”¨

## ğŸ“‹ è®­ç»ƒç¯å¢ƒå®‰è£…æ­¥éª¤

### æ­¥éª¤ 1: å®‰è£… Miniconda3
ä¸‹è½½å¹¶å®‰è£… Miniconda3 for Windows:
```bash
# ä¸‹è½½é“¾æ¥
https://docs.conda.io/en/latest/miniconda.html

# å®‰è£…åï¼Œæ‰“å¼€ Anaconda Prompt
```

### æ­¥éª¤ 2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
cd d:\idol01\homework\paper_code\tess-diffusion

# ä½¿ç”¨ environment.yaml åˆ›å»ºç¯å¢ƒ
conda env create -f environment.yaml

# è¿™å°†åˆ›å»ºåä¸º "sdlm" çš„ç¯å¢ƒï¼ŒåŒ…å«æ‰€æœ‰ä¾èµ–
```

### æ­¥éª¤ 3: æ¿€æ´»ç¯å¢ƒ
```bash
conda activate sdlm
```

### æ­¥éª¤ 4: å®‰è£…é¡¹ç›®
```bash
pip install -e .
```

### æ­¥éª¤ 5: éªŒè¯ç¯å¢ƒ
```bash
# è¿è¡Œç¯å¢ƒéªŒè¯è„šæœ¬
python verify_environment.py

# åº”è¯¥çœ‹åˆ°æ‰€æœ‰ âœ… æ ‡è®°
```

### æ­¥éª¤ 6: éªŒè¯ CUDAï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
```bash
python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"}')"
```

## ğŸš€ è®­ç»ƒæµç¨‹

### 1. æ‰©å±• Tokenizerï¼ˆé‡è¦ï¼ï¼‰
```bash
python extend_tokenizer_vocab.py \
    --train_file tess_train1_oneline.txt \
    --base_model roberta-base \
    --output_dir extended_tokenizer
```

è¿™å°†:
- ä»è®­ç»ƒæ•°æ®æå–æ‰€æœ‰å®ä½“å’Œå…³ç³»
- å°†å®ƒä»¬æ·»åŠ åˆ° tokenizer è¯æ±‡è¡¨ï¼ˆé¿å…åˆ†è¯ï¼‰
- ä¿å­˜æ‰©å±•åçš„ tokenizer åˆ° `extended_tokenizer/`

### 2. æ›´æ–°é…ç½®æ–‡ä»¶
ç¡®ä¿ `configs/tess_gpu_oneline_sc.json` ä¸­çš„è·¯å¾„æ­£ç¡®ï¼š

```json
{
  "model_name_or_path": "roberta-base",
  "tokenizer_name": "extended_tokenizer",  // ä½¿ç”¨æ‰©å±•åçš„ tokenizer
  "train_file": "tess_train1_oneline.txt",
  "validation_file": "tess_valid1_oneline.txt",
  "output_dir": "outputs/tess_training",  // è®­ç»ƒè¾“å‡ºç›®å½•
  ...
}
```

### 3. å¼€å§‹è®­ç»ƒ
```bash
python run_mlm.py configs/tess_gpu_oneline_sc.json
```

### 4. ç›‘æ§è®­ç»ƒ
```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯å¯åŠ¨ TensorBoard
tensorboard --logdir outputs/tess_training
```

### 5. è¯„ä¼°æ¨¡å‹
```bash
python eval_kg_ranking.py \
    --test_file tess_test1_oneline.txt \
    --mode tail \
    --k 1 3 10 \
    --checkpoint outputs/tess_training/checkpoint-XXXX
```

## âš™ï¸ é…ç½®è¯´æ˜

### è®­ç»ƒå‚æ•°ï¼ˆtess_gpu_oneline_sc.jsonï¼‰
```json
{
  // æ¨¡å‹å‚æ•°
  "max_seq_length": 256,                    // åºåˆ—æœ€å¤§é•¿åº¦
  "per_device_train_batch_size": 16,       // è®­ç»ƒæ‰¹æ¬¡å¤§å°
  "per_device_eval_batch_size": 16,        // è¯„ä¼°æ‰¹æ¬¡å¤§å°
  "learning_rate": 1e-4,                    // å­¦ä¹ ç‡
  
  // Diffusion å‚æ•°
  "simplex_value": 5,                       // Simplex ç¼©æ”¾å€¼
  "num_diffusion_steps": 500,               // è®­ç»ƒæ‰©æ•£æ­¥æ•°
  "num_inference_diffusion_steps": 100,     // æ¨ç†æ‰©æ•£æ­¥æ•°
  "beta_schedule": "squaredcos_improved_ddpm",
  
  // Self-conditioning
  "self_condition": "logits_addition",      // å¯ç”¨ self-conditioning
  "self_condition_zeros_after_softmax": true,
  
  // è®­ç»ƒç­–ç•¥
  "save_steps": 500,                        // æ¯ 500 æ­¥ä¿å­˜
  "save_total_limit": 5,                    // æœ€å¤šä¿ç•™ 5 ä¸ªæ£€æŸ¥ç‚¹
  "fp16": true                              // ä½¿ç”¨æ··åˆç²¾åº¦
}
```

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: CUDA ä¸å¯ç”¨
**ç—‡çŠ¶**: `torch.cuda.is_available()` è¿”å› `False`
**è§£å†³**:
1. ç¡®è®¤ GPU é©±åŠ¨å·²å®‰è£…
2. æ£€æŸ¥ CUDA ç‰ˆæœ¬ï¼ˆéœ€è¦ 11.8ï¼‰
3. é‡æ–°å®‰è£… PyTorch with CUDA: `pip install torch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 --index-url https://download.pytorch.org/whl/cu118`

### é—®é¢˜ 2: å†…å­˜ä¸è¶³
**ç—‡çŠ¶**: `RuntimeError: CUDA out of memory`
**è§£å†³**:
1. é™ä½ batch size: `"per_device_train_batch_size": 8`
2. å¯ç”¨æ¢¯åº¦ç´¯ç§¯: `"gradient_accumulation_steps": 2`
3. é™ä½åºåˆ—é•¿åº¦: `"max_seq_length": 128`

### é—®é¢˜ 3: å®ä½“è¢«åˆ†è¯
**ç—‡çŠ¶**: è¯„ä¼°æŒ‡æ ‡å¾ˆå·®ï¼Œå®ä½“æœªè¢«è¯†åˆ«
**è§£å†³**:
1. ç¡®è®¤å·²è¿è¡Œ `extend_tokenizer_vocab.py`
2. ç¡®è®¤é…ç½®ä¸­ä½¿ç”¨äº†æ‰©å±•çš„ tokenizer: `"tokenizer_name": "extended_tokenizer"`
3. è¿è¡ŒéªŒè¯: `python validate_config.py --checkpoint outputs/tess_training/checkpoint-XXX`

### é—®é¢˜ 4: è®­ç»ƒä¸æ”¶æ•›
**ç—‡çŠ¶**: Loss ä¸ä¸‹é™æˆ–æ³¢åŠ¨å¾ˆå¤§
**è§£å†³**:
1. æ£€æŸ¥å­¦ä¹ ç‡: å°è¯• `1e-5` æˆ– `5e-5`
2. æ£€æŸ¥æ•°æ®: ç¡®è®¤ `tess_train1_oneline.txt` æ ¼å¼æ­£ç¡®
3. å¯ç”¨æ¢¯åº¦è£å‰ª: `"max_grad_norm": 1.0`

## ğŸ“Š é¢„æœŸç»“æœ

### è®­ç»ƒæŒ‡æ ‡
- **Loss**: åº”è¯¥ä» ~8-10 é€æ¸é™åˆ° ~2-3
- **è®­ç»ƒæ—¶é—´**: çº¦ 4-6 å°æ—¶ï¼ˆå• GPUï¼Œå–å†³äºç¡¬ä»¶ï¼‰
- **å†…å­˜å ç”¨**: ~12-16 GB VRAMï¼ˆbatch_size=16ï¼‰

### è¯„ä¼°æŒ‡æ ‡ï¼ˆKG Rankingï¼‰
- **MR**: Mean Rank - è¶Šä½è¶Šå¥½ï¼ˆç›®æ ‡ < 100ï¼‰
- **MRR**: Mean Reciprocal Rank - è¶Šé«˜è¶Šå¥½ï¼ˆç›®æ ‡ > 0.3ï¼‰
- **Hits@1**: è¶Šé«˜è¶Šå¥½ï¼ˆç›®æ ‡ > 0.2ï¼‰
- **Hits@3**: è¶Šé«˜è¶Šå¥½ï¼ˆç›®æ ‡ > 0.4ï¼‰
- **Hits@10**: è¶Šé«˜è¶Šå¥½ï¼ˆç›®æ ‡ > 0.6ï¼‰

## ğŸ“ æ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹è®­ç»ƒå‰ï¼Œç¡®è®¤ä»¥ä¸‹é¡¹ç›®ï¼š

- [x] âœ… ä»£ç ä¿®å¤å·²åº”ç”¨ï¼ˆAdamW, torch.float32ï¼‰
- [x] âœ… å…¼å®¹æ€§éªŒè¯é€šè¿‡ (`python verify_compatibility.py`)
- [ ] ç¯å¢ƒå·²å®‰è£… (`conda env create -f environment.yaml`)
- [ ] ç¯å¢ƒéªŒè¯é€šè¿‡ (`python verify_environment.py`)
- [ ] é¡¹ç›®å·²å®‰è£… (`pip install -e .`)
- [ ] Tokenizer å·²æ‰©å±• (`python extend_tokenizer_vocab.py ...`)
- [ ] é…ç½®æ–‡ä»¶å·²æ›´æ–°ï¼ˆè·¯å¾„æ­£ç¡®ï¼‰
- [ ] GPU å¯ç”¨ï¼ˆå¦‚æœä½¿ç”¨ GPUï¼‰
- [ ] æ•°æ®æ–‡ä»¶å­˜åœ¨ï¼ˆtess_train1_oneline.txt, tess_valid1_oneline.txtï¼‰

## ğŸ¯ ä¸‹ä¸€æ­¥

ä»£ç å·²ç»å‡†å¤‡å¥½ä¸ environment.yaml ä¸­çš„ä¾èµ–é…åˆä½¿ç”¨ï¼š

1. **ç«‹å³å¯ä»¥åš**: å®‰è£…ç¯å¢ƒå¹¶å¼€å§‹è®­ç»ƒ
2. **æ–‡æ¡£å¯ç”¨**: COMPATIBILITY_ANALYSIS.md è¯¦ç»†è¯´æ˜æ‰€æœ‰å…¼å®¹æ€§ä¿¡æ¯
3. **éªŒè¯å·¥å…·**: verify_compatibility.py å’Œ verify_environment.py å¯ç”¨äºæ£€æŸ¥

**ç°åœ¨å¯ä»¥å®‰å…¨åœ°æŒ‰ç…§ä¸Šè¿°æ­¥éª¤å®‰è£…ç¯å¢ƒå¹¶å¼€å§‹è®­ç»ƒï¼**
