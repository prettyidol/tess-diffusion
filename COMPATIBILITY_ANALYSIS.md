# TESS Diffusion ä¾èµ–å…¼å®¹æ€§åˆ†æž

## çŽ¯å¢ƒé…ç½® (environment.yaml)
- Python: 3.9
- PyTorch: 2.2.0 (CUDA 11.8)
- Transformers: 4.33.3
- Diffusers: 0.27.2
- Datasets: 2.14.6
- Accelerate: 0.23.0

## ä¸»è¦å…¼å®¹æ€§é—®é¢˜åŠä¿®å¤æ–¹æ¡ˆ

### âŒ é—®é¢˜1: AdamW ä¼˜åŒ–å™¨å·²åºŸå¼ƒ
**ä½ç½®**: `sdlm/trainer.py:48` å’Œ `sdlm/trainer.py:707`
**é—®é¢˜**: `from transformers import AdamW` åœ¨ transformers 4.33.3 ä¸­å·²åºŸå¼ƒ
**å½±å“**: è®­ç»ƒå°†å¤±è´¥ï¼Œæç¤ºå¯¼å…¥é”™è¯¯
**ä¿®å¤æ–¹æ¡ˆ**: æ”¹ç”¨ `torch.optim.AdamW`

```python
# ä¿®æ”¹å‰
from transformers import AdamW
self.optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate)

# ä¿®æ”¹åŽ
from torch.optim import AdamW
self.optimizer = AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate)
```

### âœ… é—®é¢˜2: Transformers ç‰ˆæœ¬æ£€æŸ¥
**ä½ç½®**: `run_mlm.py:33`
**å½“å‰**: `check_min_version("4.25.0")`
**çŠ¶æ€**: âœ… å…¼å®¹ (4.33.3 >= 4.25.0)

### âœ… é—®é¢˜3: Diffusers API
**ä½ç½®**: `sdlm/schedulers/scheduling_simplex_ddpm.py`
**æ£€æŸ¥é¡¹**:
- `from diffusers import DDPMScheduler` âœ…
- `from diffusers.configuration_utils import register_to_config` âœ…
- `from diffusers.utils import BaseOutput` âœ…

**çŠ¶æ€**: Diffusers 0.27.2 ä¸Žä»£ç å…¼å®¹

### âš ï¸ é—®é¢˜4: Torch å¼ é‡ç±»åž‹
**ä½ç½®**: `sdlm/schedulers/scheduling_simplex_ddpm.py:66`
**é—®é¢˜**: `torch.torch.float32` åº”ä¸º `torch.float32`
**å½±å“**: å¯èƒ½å¯¼è‡´ç±»åž‹é”™è¯¯
**ä¿®å¤æ–¹æ¡ˆ**:
```python
# ä¿®æ”¹å‰
return betas, torch.tensor(alphas_cumprod, dtype=torch.torch.float32, device=device)

# ä¿®æ”¹åŽ
return betas, torch.tensor(alphas_cumprod, dtype=torch.float32, device=device)
```

### âœ… é—®é¢˜5: Datasets ç‰ˆæœ¬
**ä½ç½®**: `run_mlm.py:35`
**è¦æ±‚**: `datasets>=1.8.0`
**å½“å‰**: datasets==2.14.6
**çŠ¶æ€**: âœ… å…¼å®¹

### âœ… é—®é¢˜6: PyTorch 2.2.0 å…¼å®¹æ€§
**æ£€æŸ¥é¡¹**:
- `torch.cuda.is_available()` âœ…
- `torch.randint()` âœ…
- `torch.nn.functional` âœ…
- `torch.optim` âœ…

### âš ï¸ é—®é¢˜7: NumPy ç‰ˆæœ¬å…¼å®¹æ€§
**å½“å‰**: numpy==1.23.5
**PyTorch 2.2.0**: æŽ¨è numpy>=1.21.0,<2.0
**çŠ¶æ€**: âœ… å…¼å®¹ï¼Œä½†éœ€æ³¨æ„ä¸è¦å‡çº§åˆ° numpy 2.x

### âœ… é—®é¢˜8: Accelerate å…¼å®¹æ€§
**å½“å‰**: accelerate==0.23.0
**æ£€æŸ¥**: æ”¯æŒ PyTorch 2.2.0 å’Œ Transformers 4.33.3
**çŠ¶æ€**: âœ… å…¼å®¹

## å¿…é¡»ä¿®å¤çš„ä»£ç 

### ä¿®å¤1: sdlm/trainer.py - AdamW å¯¼å…¥
```python
# ç¬¬48è¡Œ
# ä¿®æ”¹å‰:
from transformers import AdamW

# ä¿®æ”¹åŽ:
from torch.optim import AdamW
```

### ä¿®å¤2: sdlm/schedulers/scheduling_simplex_ddpm.py - å¼ é‡ç±»åž‹
```python
# ç¬¬66è¡Œ
# ä¿®æ”¹å‰:
return betas, torch.tensor(alphas_cumprod, dtype=torch.torch.float32, device=device)

# ä¿®æ”¹åŽ:
return betas, torch.tensor(alphas_cumprod, dtype=torch.float32, device=device)
```

## å»ºè®®çš„é¢å¤–æ£€æŸ¥

### 1. æ¨¡åž‹åŠ è½½å…¼å®¹æ€§
- RoBERTa æ¨¡åž‹é…ç½®ä¸Ž transformers 4.33.3 å…¼å®¹
- è‡ªå®šä¹‰é…ç½®ç±» `RobertaDiffusionConfig` ç»§æ‰¿æ­£ç¡®

### 2. æ•°æ®åŠ è½½
- `load_dataset` API åœ¨ datasets 2.14.6 ä¸­ä¿æŒç¨³å®š
- `DatasetDict` å’Œ `load_from_disk` åŠŸèƒ½æ­£å¸¸

### 3. æ··åˆç²¾åº¦è®­ç»ƒ
- FP16 åœ¨ PyTorch 2.2.0 ä¸­æ”¯æŒè‰¯å¥½
- `torch.cuda.amp` è‡ªåŠ¨æ··åˆç²¾åº¦å¯ç”¨

## è®­ç»ƒå‰æ£€æŸ¥æ¸…å•

- [ ] ä¿®å¤ AdamW å¯¼å…¥ (trainer.py)
- [ ] ä¿®å¤ torch.torch.float32 æ‹¼å†™ (scheduling_simplex_ddpm.py)
- [ ] éªŒè¯ CUDA å¯ç”¨æ€§
- [ ] æµ‹è¯•æ•°æ®åŠ è½½å™¨
- [ ] éªŒè¯æ¨¡åž‹åˆå§‹åŒ–
- [ ] ç¡®è®¤é…ç½®æ–‡ä»¶è·¯å¾„æ­£ç¡®

## é¢„æœŸçš„è®­ç»ƒæµç¨‹

1. âœ… çŽ¯å¢ƒå®‰è£… (Miniconda + environment.yaml)
2. âœ… ä»£ç ä¿®å¤ (AdamW å’Œ dtype)
3. âœ… æ‰©å±• tokenizer (extend_tokenizer_vocab.py)
4. âœ… é…ç½®è®­ç»ƒå‚æ•° (tess_gpu_oneline_sc.json)
5. âœ… å¯åŠ¨è®­ç»ƒ (run_mlm.py)
6. âœ… è¯„ä¼°æ¨¡åž‹ (eval_kg_ranking.py)

## æ€»ç»“

**å…³é”®é—®é¢˜**: 2ä¸ªå¿…é¡»ä¿®å¤
**å…¼å®¹é—®é¢˜**: å…¶ä»–ä¾èµ–å‡å…¼å®¹
**é£Žé™©ç­‰çº§**: ðŸŸ¡ ä¸­ç­‰ (ä¿®å¤åŽå¯æ­£å¸¸è®­ç»ƒ)

ä¿®å¤ä¸Šè¿°2ä¸ªé—®é¢˜åŽï¼Œä»£ç å°†ä¸Ž environment.yaml ä¸­çš„ä¾èµ–ç‰ˆæœ¬å®Œå…¨å…¼å®¹ã€‚
